{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 10.5 실습: 하이브리드 검색 구현하기",
   "id": "95795c69c3c2a155"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 10.5.1 BM25 구현하기",
   "id": "acca232d4327ff19"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import faiss\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sentence_model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "klue_mrc_dataset = load_dataset('klue', 'mrc', split='train')\n",
    "klue_mrc_dataset = klue_mrc_dataset.train_test_split(train_size=1000, shuffle=False)['train']\n",
    "embeddings = sentence_model.encode(list(klue_mrc_dataset['context']))\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])"
   ],
   "id": "352916192c2dff1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "# 예제 10.14 BM25 클래스 구현\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from transformers import PreTrainedTokenizer\n",
    "\n",
    "\n",
    "class BM25:\n",
    "    def __init__(self, corpus: List[List[str]], tokenizer: PreTrainedTokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.corpus = corpus\n",
    "        self.tokenized_corpus = self.tokenizer(corpus, add_special_tokens=False)['input_ids']\n",
    "        self.n_docs = len(self.tokenized_corpus)\n",
    "        self.avg_doc_lens = sum(len(lst) for lst in self.tokenized_corpus) / len(self.tokenized_corpus)\n",
    "        self.idf = self._calculate_idf()\n",
    "        self.term_freqs = self._calculate_term_freqs()\n",
    "\n",
    "    def _calculate_idf(self):\n",
    "        idf = defaultdict(float)\n",
    "        for doc in self.tokenized_corpus:\n",
    "            for token_id in set(doc):\n",
    "                idf[token_id] += 1\n",
    "        for token_id, doc_frequency in idf.items():\n",
    "            idf[token_id] = math.log(((self.n_docs - doc_frequency + 0.5) / (doc_frequency + 0.5)) + 1)\n",
    "        return idf\n",
    "\n",
    "    def _calculate_term_freqs(self):\n",
    "        term_freqs = [defaultdict(int) for _ in range(self.n_docs)]\n",
    "        for i, doc in enumerate(self.tokenized_corpus):\n",
    "            for token_id in doc:\n",
    "                term_freqs[i][token_id] += 1\n",
    "        return term_freqs\n",
    "\n",
    "    def get_scores(self, query: str, k1: float = 1.2, b: float = 0.75):\n",
    "        query = self.tokenizer([query], add_special_tokens=False)['input_ids'][0]\n",
    "        scores = np.zeros(self.n_docs)\n",
    "        for q in query:\n",
    "            idf = self.idf[q]\n",
    "            for i, term_freq in enumerate(self.term_freqs):\n",
    "                q_frequency = term_freq[q]\n",
    "                doc_len = len(self.tokenized_corpus[i])\n",
    "                score_q = idf * (q_frequency * (k1 + 1)) / ((q_frequency) + k1 * (1 - b + b * (doc_len / self.avg_doc_lens)))\n",
    "                scores[i] += score_q\n",
    "        return scores\n",
    "\n",
    "    def get_top_k(self, query: str, k: int):\n",
    "        scores = self.get_scores(query)\n",
    "        top_k_indices = np.argsort(scores)[-k:][::-1]\n",
    "        top_k_scores = scores[top_k_indices]\n",
    "        return top_k_scores, top_k_indices"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 예제 10.15 BM25 점수 계산 확인해 보기\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('klue/roberta-base')\n",
    "\n",
    "bm25 = BM25(['안녕하세요', '반갑습니다', '안녕 서울'], tokenizer)\n",
    "bm25.get_scores('안녕')"
   ],
   "id": "be0ed0d49ee92455",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 예제 10.16 BM25 검색 결과의 한계\n",
    "\n",
    "\n",
    "# BM25 검색 준비\n",
    "bm25 = BM25(list(klue_mrc_dataset['context']), tokenizer)\n",
    "\n",
    "query = \"이번 연도에는 언제 비가 많이 올까?\"\n",
    "_, bm25_search_ranking = bm25.get_top_k(query, 100)\n",
    "\n",
    "for idx in bm25_search_ranking[:3]:\n",
    "    print(klue_mrc_dataset['context'][int(idx)][:50])\n"
   ],
   "id": "5f03510de6e109b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 예제 10.17 BM25 검색 결과의 장점\n",
    "\n",
    "query = klue_mrc_dataset[3]['question']  # 로버트 헨리 딕이 1946년에 매사추세츠 연구소에서 개발한 것은 무엇인가?\n",
    "_, bm25_search_ranking = bm25.get_top_k(query, 100)\n",
    "\n",
    "for idx in bm25_search_ranking[:3]:\n",
    "    print(klue_mrc_dataset['context'][int(idx)][:50])"
   ],
   "id": "6e6c5a0a792037b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 10.5.2 상호 순위 조합 구현하기",
   "id": "a31e6590f689a8cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 예제 10.18 상호 순위 조합 함수 구현\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def reciprocal_rank_fusion(rankings: List[List[int]], k=5):\n",
    "    rrf = defaultdict(float)\n",
    "    for ranking in rankings:\n",
    "        for i, doc_id in enumerate(ranking, 1):\n",
    "            rrf[doc_id] += 1.0 / (k + i)\n",
    "    return sorted(rrf.items(), key=lambda x: x[1], reverse=True)"
   ],
   "id": "6dc213cb43b29bf5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 예제 10.19 예시 데이터에 대한 상호 순위 조합 결과 확인하기\n",
    "\n",
    "\n",
    "def dense_vector_search(query: str, k: int):\n",
    "    query_embedding = sentence_model.encode([query])\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    return distances[0], indices[0]\n",
    "\n",
    "\n",
    "def hybrid_search(query, k=20):\n",
    "    _, dense_search_ranking = dense_vector_search(query, 100)\n",
    "    _, bm25_search_ranking = bm25.get_top_k(query, 100)\n",
    "\n",
    "    results = reciprocal_rank_fusion([dense_search_ranking, bm25_search_ranking], k=k)\n",
    "    return results"
   ],
   "id": "de582918c2d6a5db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 예제 10.21 예시 데이터에 대한 하이브리드 검색 결과 확인\n",
    "\n",
    "query = \"이번 연도에는 언제 비가 많이 올까?\"\n",
    "print(\"검색 쿼리 문장: \", query)\n",
    "results = hybrid_search(query)\n",
    "for idx, score in results[:3]:\n",
    "    print(klue_mrc_dataset['context'][int(idx)][:50])\n",
    "\n",
    "print(\"=\" * 80)\n",
    "query = klue_mrc_dataset[3]['question']  # 로버트 헨리 딕이 1946년에 매사추세츠 연구소에서 개발한 것은 무엇인가?\n",
    "print(\"검색 쿼리 문장: \", query)\n",
    "\n",
    "results = hybrid_search(query)\n",
    "for idx, score in results[:3]:\n",
    "    print(klue_mrc_dataset['context'][int(idx)][:50])"
   ],
   "id": "d1ff8f61544cfd16",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
