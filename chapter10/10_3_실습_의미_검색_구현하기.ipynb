{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac00c82f65450a43",
   "metadata": {},
   "source": [
    "# 10.3 실습: 의미 검색 구현하기\n",
    "- Semantic Search\n",
    "- 단순히 키워드 매칭을 통한 검색이 아니라, 밀집 임베딩을 이용해 문장이나 문서의 의미를 고려한 검색을 수행하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec128b5b3fe0a80",
   "metadata": {},
   "source": [
    "## 10.3.1 의미검색 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "id": "cb91d1f615b620c1",
   "metadata": {},
   "source": [
    "# 예제 10.8 실습에 사용할 모델과 데이터셋 불러오기\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "klue_mrc_dataset = load_dataset('klue', 'mrc', split='train')\n",
    "klue_mrc_dataset"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "548bd6606848dee9",
   "metadata": {},
   "source": [
    "sentence_model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "sentence_model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a383c0860d9b85f9",
   "metadata": {},
   "source": [
    "# 예제 10.9 실습 데이터에서 1,000개만 선택하고 문장 임베딩으로 변환\n",
    "\n",
    "train_data_set = klue_mrc_dataset.train_test_split(train_size=1000, shuffle=False)['train']\n",
    "train_data_set"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c0bc1cf59784e1b6",
   "metadata": {},
   "source": [
    "embeddings = sentence_model.encode(list(train_data_set['context']))\n",
    "embeddings.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "83c695b08a521ff4",
   "metadata": {},
   "source": [
    "# 예제 10.10 KNN 검색 인덱스를 생성하고 문장 임베딩 저장\n",
    "\n",
    "import faiss\n",
    "\n",
    "# 인덱스 만들기\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "\n",
    "# 인덱스에 임베딩 저장하기\n",
    "index.add(embeddings)\n",
    "index"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "28f2483cc65ec52c",
   "metadata": {},
   "source": [
    "# 예제 10.11 의미 검색의 장점\n",
    "\n",
    "query = '이번 연도에는 언제 비가 많이 올까?'\n",
    "query_embeddings = sentence_model.encode([query])\n",
    "distances, indices = index.search(query_embeddings, 3)  # query_embeddings와 가장 가까운 3개의 문장 검색\n",
    "\n",
    "indices"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fa71221c4def85e9",
   "metadata": {},
   "source": [
    "for idx in indices[0]:\n",
    "    print(idx, train_data_set['context'][int(idx)], '\\n-------------------------------')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "21a2a84d75648c12",
   "metadata": {},
   "source": [
    "# 예제 10.12 의미 검색의 한계\n",
    "\n",
    "query = klue_mrc_dataset[3]['question']  # 로버트 헨리 딕이 1946년에 매사추세츠 연구소에서 개발한 것은 무엇인가?\n",
    "query_embedding = sentence_model.encode([query])\n",
    "distances, indices = index.search(query_embedding, 3)\n",
    "\n",
    "for idx in indices[0]:\n",
    "    print(klue_mrc_dataset['context'][int(idx)][:50])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d1f3e1b1b67a1d58",
   "metadata": {},
   "source": [
    "## 10.3.2 라마인덱스에서 Sentence-Transformers 모델 사용하기\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "2d6d0ef15212c2e0",
   "metadata": {},
   "source": [
    "# 예제 10.13 라마인덱스에서 Sentence-Transformers 임베딩 모델 활용\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, ServiceContext\n",
    "from llama_index.core import Document, Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "Settings.llm = None  # LLM을 사용하지 않으므로 None으로 설정\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\")\n",
    "\n",
    "# 로컬 모델 활용하기\n",
    "# service_context = ServiceContext.from_defaults(embed_model=\"local\")\n",
    "\n",
    "text_list = klue_mrc_dataset[:100]['context']\n",
    "documents = [Document(text=t) for t in text_list]\n",
    "\n",
    "index_llama = VectorStoreIndex.from_documents(documents)\n",
    "index_llama"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "976c71608575367b",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
